# webscraping


Ce projet utilise Python pour effectuer le webscraping d'un site web donn√©. Le code utilise les biblioth√®ques selenium, fake_useragent, colorama, csv, pandas et requests pour effectuer les op√©rations de webscraping.

Installation

Cloner ce d√©p√¥t sur votre machine locale.
Assurez-vous d'avoir Python 3 install√© sur votre machine.

Installez les biblioth√®ques requises √† l'aide de la commande suivante :

pip install selenium fake_useragent colorama csv pandas requests
T√©l√©chargez et installez Google Chrome sur votre machine locale.
T√©l√©chargez et installez le chromedriver correspondant √† la version de Google Chrome install√©e sur votre machine locale.
D√©placez le fichier chromedriver t√©l√©charg√© dans le m√™me dossier que le code Python.

Utilisation

Ex√©cutez le fichier main.py en utilisant la commande suivante :

python main.py
Le programme va s'ex√©cuter et effectuer le webscraping en utilisant les informations fournies dans le fichier webscraping.json et le fichier .csv.


Configuration

Le fichier webscraping.json contient les informations de configuration pour le programme de webscraping. Les diff√©rentes options sont :

url : L'URL du site web √† scraper.
headless : Sp√©cifie si le navigateur doit √™tre en mode "headless" ou non. Les valeurs possibles sont "yes" ou "no".
proxyless : Sp√©cifie si le programme doit utiliser un proxy pour le webscraping. Les valeurs possibles sont "yes" ou "no".
sleep_time : Le temps de pause entre chaque requ√™te, en secondes.
max_retry : Le nombre maximal de tentatives √† effectuer si une requ√™te √©choue.
timeout : Le temps maximal pour attendre qu'une page se charge, en secondes.

#üö®Avertissement
Le webscraping de sites web sans autorisation peut √™tre ill√©gal. Veuillez vous assurer d'avoir le droit de scraper le site web avant d'utiliser ce programme.
